# Initialize RAM from compressed init data generated by the Keil toolchain
#
# The Keil ARM toolchain stores the initialization data for .rwdata in a
# compressed block at the end of the flash binary. For static analysis
# it's helpful to unpack that data and load it into the disassembler.
#
# Usage:
# ======
#
# 1. Create an uninitialized block called "ram" in your memory map,
#    covering the entire SRAM of your device.
#
# 2. Find the "__scatterload" function. This should be very easy if you have
#    your reset vector right - it's one of the first functions in the program
#    flow after the reset vector, and it's going through a table of parameters
#    and function pointers, calling each in succession.
#
#    So far I know of two types of these, one starts like so:
#
#      ldr r4, [pointer close to the end of the flash image]
#      ldr r5, #1
#      ldr r6, [pointer to N * 0x10 bytes behind the first]
#      b   <into a loop>
#
#    And the other type starts like so:
#
#      adr r0, [first of two dwords at the end of the function]
#      ldmia r0!, { r4, r5 }
#
# 3. With the cursor inside the __scatterload function, launch this script.
#
# 4. OPTIONAL: If the script cannot identify the scatterload function by itself
#    you can explicitly tell it where the jump table is:
#    Analyze the function to find the jump table it's using, and then
#    select the entire jump table and run the script again.
#
# Expected result:
# ================
#
# The script will break your RAM block into three parts:
#   ram.init  - initialized data containing the uncompressed rwdata block
#   ram.clear - zero-initialized data for the bss section
#   ram.undef - the rest of RAM which is left uninitialized
#
# Feel free to rename these blocks afterwards.
#
# The script will also annotate the __scatterload function and all its
# tables along the way.
#
# Compression support:
# ====================
#
# Keil supports several compression algorithms; since there's no clear
# indication of which algorithm is used in a binary, the script simply
# tries them all and picks the one that decompresses cleanly.
#
# Currently supported algos:
#   No compression (__scatterload_copy)
#   Simple RLE (__decompress0)
#   RLE with LZ77 on small repeats (__decompress1)
#   Complex LZ77 (__decompress2)
#
#
# Copyright 2020 Joachim Fenkes <github@dojoe.net>
# License: GPLv3
#
# @author Joachim Fenkes <github@dojoe.net>
# @category ARM
# @keybinding
# @menupath
# @toolbar

from __future__ import print_function
from array import array
from ghidra.program.model.symbol import SourceType
from ghidra.program.model.data import PointerDataType, StructureDataType, UnsignedIntegerDataType, FunctionDefinitionDataType, ParameterDefinitionImpl, VoidDataType, ArrayDataType, ByteDataType
from ghidra.program.model.address import AddressRangeImpl
from ghidra.app.cmd.function import ApplyFunctionSignatureCmd

memory = currentProgram.getMemory()
listing = currentProgram.getListing()
symbols = currentProgram.getSymbolTable()
dtm = currentProgram.getDataTypeManager()


def yikes(*args):
    "A quick way to bail with an error message"
    print("ERROR:", *args)
    exit(1)


class AtomicContext(object):
    """
    A simple context manager to run a series of operations as a complete DB transaction,
    making the entire series atomic.
    The transaction is committed only if the context completes without an unhandled exception.
    """
    def __enter__(self):
        start()
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        end(exc_type is None)


def read_uints(address, nints):
    # Jython won't let us submit an unsigned array to getInts, so create a signed one first
    signed_ints = array("i", [0] * nints)
    if memory.getInts(address, signed_ints) != nints:
        yikes("Unable to read %d 32bit integers starting at %s" % (nints, address))

    # cast into unsigned before returning
    return array("I", signed_ints.tostring())


def read_bytes(address, nbytes):
    # Jython won't let us submit an unsigned array to getBytes, so create a signed one first
    signed_chars = array("b", [0] * nbytes)
    if memory.getBytes(address, signed_chars) != nbytes:
        yikes("Unable to read %d bytes integers starting at %s" % (nbytes, address))

    # cast into unsigned before returning
    return array("B", signed_chars.tostring())


def get_load_data(insn):
    """
    If the instruction is a plain load of a 32bit word into a register,
    return the value that is loaded and the address from which it is loaded,
    otherwise return None
    """
    pcode = insn.getPcode()
    if len(pcode) == 1:
        op = pcode[0]
        if op.getOpcode() == op.COPY and op.getOutput().isRegister() and op.getNumInputs() == 1:
            input = op.getInput(0)
            if input.isAddress():
                addr = input.getAddress()
                return addr.getNewAddress(memory.getInt(addr)), addr

    return None


def unpack_rle(packed, unpacked):
    """
    Decompress data compressed by the Keil RLE (__decompress0) algorithm
    """
    ctrl = packed.pop(0)
    literal_len = ((ctrl & 0xF) or packed.pop(0)) - 1
    zero_len = ((ctrl >> 4) or packed.pop(0)) - 1

    # copy literals, append zeros
    unpacked.extend(packed[:literal_len] + ([0] * zero_len))
    del packed[:literal_len]


def unpack_rlz77(packed, unpacked):
    """
    Decompress data compressed by the Keil RLE/LZ77 mixed (__decompress1) algorithm
    """
    ctrl = packed.pop(0)
    literal_len = ((ctrl & 7) or packed.pop(0)) - 1
    backref_len = (ctrl >> 4) or packed.pop(0)

    # copy literals
    unpacked.extend(packed[:literal_len])
    del packed[:literal_len]

    # process backrefs or zeros
    if ctrl & 8:
        offset = packed.pop(0)
        for _ in range(backref_len + 2):
            unpacked.append(unpacked[-offset])
    else:
        unpacked.extend([0] * backref_len)


def unpack_lz77(packed, unpacked):
    """
    Decompress data compressed by the Keil LZ77 (__decompress2) algorithm
    """
    ctrl = packed.pop(0)
    literal_len = ((ctrl & 3) or packed.pop(0)) - 1
    backref_len = ((ctrl >> 4) or packed.pop(0)) + 2

    # copy literals
    unpacked.extend(packed[:literal_len])
    del packed[:literal_len]

    # process backrefs
    if backref_len:
        offset_lo = packed.pop(0)
        offset_hi = (ctrl >> 2) & 3
        if offset_hi == 3:
            offset_hi = packed.pop(0)
        offset = offset_hi * 0x100 + offset_lo

        for _ in range(backref_len):
            unpacked.append(unpacked[-offset])


unpack_cores = [
    (unpack_rle,   "__decompress0", "RLE"),
    (unpack_rlz77, "__decompress1", "RLE/LZ77 mixed"),
    (unpack_lz77,  "__decompress2", "LZ77")
]


def unpack(packed, unpacked_size, core):
    """
    Decompress Keil compressed data using the specified algorithm core
    """
    core_function, _, core_name = core
    packed = list(packed)
    unpacked = list()
    print("Attempting %s decompression" % core_name)
    try:
        while len(unpacked) < unpacked_size:
            core_function(packed, unpacked)
    except IndexError:
        print("  Decompression failed: Ran out of compressed data")
        return None

    if len(unpacked) != unpacked_size:
        print("  Decompression failed: Too much decompressed data")
        return None

    # If we have only zero-bytes left over and less than 16 of them,
    # we assume it's padding and let it slide
    if len(packed) > 15 or any(packed):
        print("  Decompression failed: Leftover compressed data")
        return None

    print("  Decompression successful!")
    return unpacked


class KeilRAMInit(object):
    """
    The main flow of the script, put into a class so we can break out logical sections
    of the flow into methods and store intermediate data in the class instance.
    """
    def run(self):
        """
        The high-level flow
        """
        self.ram_block = memory.getBlock("ram")
        if not self.ram_block or self.ram_block.isInitialized():
            yikes("No uninitialized memory block named 'ram' found")

        if currentSelection is None or currentSelection.isEmpty():
            self.scatterload_function = listing.getFunctionContaining(currentAddress)
            if not self.scatterload_function:
                yikes("Please launch the script from within a function")
            self.find_scatterload_table()
        else:
            self.scatterload_table = currentSelection.getFirstRange()

        print("Scatterload table at", self.scatterload_table)

        self.create_types()
        self.parse_scatterload_table()

        if not (self.data_init_start and self.ram_clear_start):
            yikes("Data init or RAM clear entry are missing from the scatterload table")

        print("Initialization data at %s (%d bytes)" % (self.data_init_start, self.data_size_packed))
        print("Uncompressed initialized data size: %d bytes" % self.data_size_unpacked)
        print("Zeroed data at %s (%d bytes)" % (self.ram_clear_start, self.ram_clear_size))

        self.uncompress_init_data()
        self.create_ram_blocks()

        print(r"All done \o/")

    def create_types(self):
        """
        Create custom data types if the don't exist yet (why would they?).
        """
        self.function_type = dtm.getDataType("/ScatterLoadSubFunction")
        if not self.function_type:
            self.function_type = FunctionDefinitionDataType("ScatterLoadSubFunction")
            self.function_type.setReturnType(VoidDataType.dataType)
            self.function_type.setArguments([
                ParameterDefinitionImpl("source", PointerDataType(VoidDataType.dataType), None),
                ParameterDefinitionImpl("destination", PointerDataType(VoidDataType.dataType), None),
                ParameterDefinitionImpl("dest_size", UnsignedIntegerDataType.dataType, None)
            ])

        self.table_entry_type = dtm.getDataType("/ScatterLoadTableEntry")
        if not self.table_entry_type:
            self.table_entry_type = StructureDataType("ScatterLoadTableEntry", 0)
            self.table_entry_type.add(PointerDataType(VoidDataType.dataType), 0, "source", "Source data for RAM initialization")
            self.table_entry_type.add(PointerDataType(VoidDataType.dataType), 0, "destination", "Start of target area in RAM")
            self.table_entry_type.add(UnsignedIntegerDataType.dataType, 0, "dest_size", "Length of target area in RAM, in bytes")
            self.table_entry_type.add(PointerDataType(self.function_type), 0, "func", "Function to be called")

    def extract_scatterload_A(self):
        """
        Extract the scatterload table pointers from a function that loads the pointers individually
        """
        load_values = []
        for i, insn in enumerate(listing.getInstructions(self.scatterload_function.getEntryPoint(), True)):
            pair = get_load_data(insn)
            if pair:
                load_values.append(pair)
                if len(load_values) == 2:
                    break
            if i == 8:
                return None

        print("Type A scatterload function identified")

        retval = []
        for pointed, pointer in sorted(load_values):
            listing.clearCodeUnits(pointer, pointer.add(4), False)
            listing.createData(pointer, PointerDataType.dataType)
            retval.append(pointed)

        return retval

    def extract_scatterload_B(self):
        """
        Extract the pointers from a function that uses a ldmia instruction to load both pointers at once
        """
        insn_adr = listing.getInstructionAt(self.scatterload_function.getEntryPoint())
        insn_ldmia = insn_adr.getNext()
        ldmia_op1 = insn_ldmia.getOpObjects(1)

        # We're looking for an adr/ldmia combination that loads two consecutive values into two regs
        if not (insn_adr.mnemonicString == "adr"
                and insn_ldmia.mnemonicString == "ldmia"
                and insn_adr.getRegister(0) == insn_ldmia.getRegister(0)
                and ldmia_op1 and len(ldmia_op1) == 2):
            return None

        print("Type B scatterload function identified")

        # The stored pointers to the scatterload table are offsets relative to the location of the first pointer
        offsets = currentAddress.getNewAddress(insn_adr.getOpObjects(1)[0].getValue())
        listing.clearCodeUnits(offsets, offsets.add(8), False)
        listing.createData(offsets, UnsignedIntegerDataType.dataType)
        listing.createData(offsets.add(4), UnsignedIntegerDataType.dataType)

        return [offsets.add(offset) for offset in read_uints(offsets, 2)]

    def find_scatterload_table(self):
        """
        Assuming we're really looking at the __scatterload function, extract
        the scatterload table location and size.
        """
        table_pointers = self.extract_scatterload_A() or self.extract_scatterload_B()
        if not table_pointers:
            print("Cannot identify the current function as a scatterload function :(")
            print("If you're certain this is it please help the script along:")
            print(" 1. Find the scatterload table yourself - N*16 bytes large and referenced by this function")
            print(" 2. Select the entire table and re-run the script")
            exit(1)

        scatterload_table_start, scatterload_table_end = table_pointers
        symbols.createLabel(scatterload_table_start, "Region$$Table$$Base", SourceType.USER_DEFINED)
        symbols.createLabel(scatterload_table_end, "Region$$Table$$Limit", SourceType.USER_DEFINED)

        self.scatterload_function.setName("__scatterload", SourceType.USER_DEFINED)
        self.scatterload_table = AddressRangeImpl(scatterload_table_start, scatterload_table_end.subtract(1))

    def parse_scatterload_table(self):
        """
        Go through the scatterload table and identify the calls to unpack the init data and
        clear the bss section.
        """
        self.data_init_start = None
        self.data_size_packed = None
        self.data_size_unpacked = None
        self.ram_clear_start = None
        self.ram_clear_size = None

        if self.scatterload_table.getLength() % 0x10:
            yikes("Scatterload table size not a multiple of 0x10")

        scatterload_nentries = self.scatterload_table.getLength() / 0x10
        if scatterload_nentries < 2:
            yikes("Scatterload table too small to contain a decompress and clear entry")

        # Actually iterating might be unnecessary because the table layout is identical
        # in all targets I've seen so far, but what do I know.
        # The one assumption in here is that the unpack call comes _before_ the clear call.
        for entry in range(scatterload_nentries):
            addr = self.scatterload_table.getMinAddress().add(entry * 0x10)
            listing.clearCodeUnits(addr, addr.add(0x10), False)
            listing.createData(addr, self.table_entry_type)
            entry = read_uints(addr, 4)

            function_name = None
            is_rwdata_init_function = False
            if entry[1] == self.ram_block.getStart().getOffset():
                print("Init data call found:", entry)
                is_rwdata_init_function = True

                self.data_init_start = addr.getNewAddress(entry[0])
                self.data_size_unpacked = entry[2]

            elif self.data_init_start and entry[1] == self.ram_block.getStart().getOffset() + self.data_size_unpacked:
                print("Clear memory call found:", entry)
                function_name = "__scatterload_zeroinit"

                self.data_size_packed = entry[0] - self.data_init_start.getOffset()
                self.ram_clear_start = addr.getNewAddress(entry[1])
                self.ram_clear_size = entry[2]

            function_addr = addr.getNewAddress(entry[3])
            function = createFunction(function_addr, function_name)
            # Using commands for high-level operations is the "Ghidra Way" it seems:
            # https://github.com/NationalSecurityAgency/ghidra/issues/1126
            ApplyFunctionSignatureCmd(function_addr, self.function_type, SourceType.USER_DEFINED, True, False).applyTo(currentProgram)
            if is_rwdata_init_function:
                self.rwdata_init_function = function or getFunctionAt(function_addr)

    def uncompress_init_data(self):
        """
        Uncompress the init data by trying all available decompressors.
        """
        symbols.createLabel(self.data_init_start, "rwdata_init", SourceType.USER_DEFINED).setPrimary()
        listing.clearCodeUnits(self.data_init_start, self.data_init_start.add(self.data_size_packed), False)
        listing.createData(self.data_init_start, ArrayDataType(ByteDataType.dataType, self.data_size_packed, 1))

        packed_data = read_bytes(self.data_init_start, self.data_size_packed)
        if self.data_size_packed == self.data_size_unpacked:
            print("Initialization data packed size equals unpacked size, assuming no compression")
            self.unpacked_data = packed_data
            self.rwdata_init_function.setName("__scatterload_copy", SourceType.USER_DEFINED)
        else:
            print("Uncompressing initialization data")
            for core in unpack_cores:
                self.unpacked_data = unpack(packed_data, self.data_size_unpacked, core)
                if self.unpacked_data is not None:
                    self.rwdata_init_function.setName(core[1], SourceType.USER_DEFINED)
                    break
            else:
                yikes("Failed to uncompress initialization data")

    def create_ram_blocks(self):
        """
        Split the ram block into parts, and initialize them with our unpacked data
        and zeros respectively.
        """
        print("Creating and initializing RAM blocks")

        undef_start = self.ram_clear_start.add(self.ram_clear_size)

        ram_init = self.ram_block
        ram_init.setName("ram.init")

        memory.split(ram_init, self.ram_clear_start)
        ram_clear = memory.getBlock(self.ram_clear_start)
        ram_clear.setName("ram.clear")

        memory.split(ram_clear, undef_start)
        ram_undef = memory.getBlock(undef_start)
        ram_undef.setName("ram.undef")

        ram_clear = memory.convertToInitialized(ram_clear, 0)

        ram_init = memory.convertToInitialized(ram_init, 0)
        ram_init.putBytes(ram_init.getStart(), array("b", array("B", self.unpacked_data).tostring()))


# Run the entire flow within a nice atomic context so the whole script can be undone as a single operation
with AtomicContext():
    KeilRAMInit().run()
